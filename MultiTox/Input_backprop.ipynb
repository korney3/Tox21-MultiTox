{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data_multitox as ld\n",
    "import dataloaders_sigma as dl\n",
    "from Model_train_test_regression import Net, EarlyStopping, train, test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as td\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import sys \n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler#StandardScaler\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# number of conformers created for every molecule\n",
    "NUM_CONFS = 100\n",
    "\n",
    "# amount of chemical elements taking into account\n",
    "AMOUNT_OF_ELEM = 9\n",
    "\n",
    "# amount of target values\n",
    "TARGET_NUM = 29\n",
    "\n",
    "#dataset folder\n",
    "# DATASET_PATH=\"~/Tox21-MultiTox/MultiTox\"\n",
    "DATASET_PATH=\"./\"\n",
    "\n",
    "#logs path\n",
    "LOG_PATH=os.path.join(DATASET_PATH,\"logs_sigma_right\")\n",
    "\n",
    "\n",
    "#models path\n",
    "MODEL_PATH=os.path.join(DATASET_PATH,\"models_sigma_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NUM=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,\"logs_sigma_right\",'exp_'+str(EXPERIMENT_NUM),str(EXPERIMENT_NUM)+'_parameters.json'),'r') as f:\n",
    "  args = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EPOCHS_NUM': 100,\n",
       " 'PATIENCE': 25,\n",
       " 'SIGMA': 1.2,\n",
       " 'BATCH_SIZE': 128,\n",
       " 'TRANSF': 'g',\n",
       " 'NUM_EXP': '19',\n",
       " 'VOXEL_DIM': 50,\n",
       " 'LEARN_RATE': 1e-05,\n",
       " 'SIGMA_TRAIN': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = os.path.join(LOG_PATH,'exp_'+str(EXPERIMENT_NUM))\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_PATH,'exp_'+str(EXPERIMENT_NUM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "GeForce GTX 1080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Start loading dataset...\n",
      "Initial dataset size =  13091\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "print('Start loading dataset...')\n",
    "\n",
    "# get dataset without duplicates from csv\n",
    "data = pd.read_csv(os.path.join(DATASET_PATH,'database', 'MultiTox.csv'))\n",
    "props = list(data)[1:]\n",
    "scaler = MinMaxScaler()\n",
    "data[props]=scaler.fit_transform(data[props])\n",
    "\n",
    "# create elements dictionary\n",
    "#     elements = ld.create_element_dict(data, amount=AMOUNT_OF_ELEM+1)\n",
    "elements={'N':0,'C':1,'Cl':2,'I':3,'Br':4,'F':5,'O':6,'P':7,'S':8}\n",
    "\n",
    "# read databases to dictionary\n",
    "#     conf_calc = ld.reading_sql_database(database_dir='./dat/')\n",
    "with open(os.path.join(DATASET_PATH,'many_elems.json'), 'r') as fp:\n",
    "    conf_calc = json.load(fp)\n",
    "\n",
    "keys=list(conf_calc.keys())\n",
    "print ('Initial dataset size = ', len(keys))\n",
    "\n",
    "new_conf_calc={}\n",
    "for smiles in conf_calc.keys():\n",
    "    for conf_num in conf_calc[smiles]:\n",
    "        if smiles in new_conf_calc.keys():\n",
    "            new_conf_calc[smiles][int(conf_num)]=conf_calc[smiles][conf_num]\n",
    "        else:\n",
    "            new_conf_calc[smiles]={}\n",
    "            new_conf_calc[smiles][int(conf_num)]=conf_calc[smiles][conf_num]\n",
    "\n",
    "conf_calc=new_conf_calc\n",
    "\n",
    "elems = []\n",
    "for key in keys:\n",
    "    conformers=list(conf_calc[key].keys())\n",
    "    for conformer in conformers:\n",
    "        try:\n",
    "            energy = conf_calc[key][conformer]['energy']\n",
    "            elems = list(set(elems+list(conf_calc[key][conformer]['coordinates'].keys())))\n",
    "        except:\n",
    "            del conf_calc[key][conformer]\n",
    "    if set(conf_calc[key].keys())!=set(range(100)):\n",
    "          del conf_calc[key]\n",
    "    elif conf_calc[key]=={}:\n",
    "        del conf_calc[key]\n",
    "\n",
    "print ('Post-processed dataset size = ', len(list(conf_calc.keys())))\n",
    "# create indexing and label_dict for iteration\n",
    "indexing, label_dict = ld.indexing_label_dict(data, conf_calc)\n",
    "# print('Dataset has been loaded, ', int(time.time()-start_time),' s')\n",
    "\n",
    "# start_time=time.time()\n",
    "# create train and validation sets' indexes\n",
    "print('Neural network initialization...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes, test_indexes, _, _ = train_test_split(np.arange(0, len(conf_calc.keys())),\n",
    "                                                     np.arange(0, len(conf_calc.keys())), test_size=0.2,\n",
    "                                                     random_state=115)\n",
    "\n",
    "train_set = dl.Cube_dataset(conf_calc, label_dict, elements, indexing, train_indexes, dim = args['VOXEL_DIM'])\n",
    "train_generator = td.DataLoader(train_set, batch_size=args['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "test_set = dl.Cube_dataset(conf_calc, label_dict, elements, indexing, test_indexes, dim = args['VOXEL_DIM'])\n",
    "test_generator = td.DataLoader(test_set, batch_size=args['BATCH_SIZE'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visualization(data,model,elements,grad_step=10**3,name=''):\n",
    "    import matplotlib.pyplot as plt\n",
    "    inv_elems = {v: k for k, v in elements.items()}\n",
    "    print(name)\n",
    "\n",
    "    fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    \n",
    "    ax[0].imshow(data.cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[0].set_title('Molecule projection')\n",
    "    ax[1].imshow((data-grad_step*data.grad).cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[1].set_title('Molecule Gradient descent')\n",
    "    with torch.no_grad():\n",
    "        gauss_blur = model.blur(data)\n",
    "\n",
    "    ax[2].imshow(gauss_blur.cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[2].set_title('Blurred molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    molecules = data.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(molecules):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "        ax[i//3,i%3].set_title(inv_elems[i])\n",
    "    fig.suptitle('Atom types in molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    molecules_blur = gauss_blur.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(molecules_blur):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "        ax[i//3,i%3].set_title(inv_elems[i])\n",
    "    fig.suptitle('Blurred atom types in molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    grads = data.grad.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(grads):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "    fig.suptitle('Grads for atom types in molecule')    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visualization_input_as_parameter(model,elements,grad_step=10**3,name=''):\n",
    "    import matplotlib.pyplot as plt\n",
    "    inv_elems = {v: k for k, v in elements.items()}\n",
    "    print(name)\n",
    "\n",
    "    fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    \n",
    "    data=model.x_input\n",
    "    \n",
    "    ax[0].imshow(data.cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[0].set_title('Molecule projection')\n",
    "    ax[1].imshow((data-grad_step*data.grad).cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[1].set_title('Molecule Gradient descent')\n",
    "    with torch.no_grad():\n",
    "        gauss_blur = model.blur(data)\n",
    "\n",
    "    ax[2].imshow(gauss_blur.cpu().detach().sum(dim=0).sum(dim=0).sum(dim=0))\n",
    "    ax[2].set_title('Blurred molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    molecules = data.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(molecules):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "        ax[i//3,i%3].set_title(inv_elems[i])\n",
    "    fig.suptitle('Atom types in molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    molecules_blur = gauss_blur.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(molecules_blur):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "        ax[i//3,i%3].set_title(inv_elems[i])\n",
    "    fig.suptitle('Blurred atom types in molecule')\n",
    "    plt.show()\n",
    "    \n",
    "    grads = data.grad.cpu().detach().sum(dim=0)\n",
    "\n",
    "    fig,ax = plt.subplots(3,3,figsize=(15,15))\n",
    "    for i,grad in enumerate(grads):\n",
    "        ax[i//3,i%3].imshow(grad.sum(dim=0))\n",
    "    fig.suptitle('Grads for atom types in molecule')    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(dim=args['VOXEL_DIM'], num_elems=AMOUNT_OF_ELEM, num_targets=TARGET_NUM, elements=elements, transformation=args['TRANSF'],device=device,sigma_0 = args['SIGMA'],sigma_trainable = args['SIGMA_TRAIN'], x_trainable=True, x_input=molecule)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH,'checkpoint.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "for batch_idx, (molecule, target) in enumerate(train_generator):\n",
    "    if batch_idx<9:\n",
    "        continue\n",
    "    molecule = Variable(molecule.to(device),requires_grad=True)\n",
    "    model = Net(dim=args['VOXEL_DIM'], num_elems=AMOUNT_OF_ELEM, num_targets=TARGET_NUM, elements=elements, transformation=args['TRANSF'],device=device,sigma_0 = args['SIGMA'],sigma_trainable = args['SIGMA_TRAIN'], x_trainable=True, x_input=molecule)\n",
    "    model=model.to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH,'checkpoint.pt')))\n",
    "    model.x_input=Parameter(molecule,requires_grad=True)\n",
    "    target = target.to(device)\n",
    "    # set gradients to zero\n",
    "    output = model(model.x_input)\n",
    "    # create mask to get rid of Nan's in target\n",
    "    mask = (target == target)\n",
    "    output_masked = torch.masked_select(output, mask).type_as(output)\n",
    "    target_masked = torch.masked_select(target, mask).type_as(output)\n",
    "    criterion=nn.MSELoss()\n",
    "    loss = criterion(output_masked, target_masked)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
